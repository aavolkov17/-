{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, roc_curve, roc_auc_score\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных нет пропусков. Все типы данных определены верно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Количество дубликатов в данных - 0\n"
     ]
    }
   ],
   "source": [
    "print('\\nКоличество дубликатов в данных -', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных нет дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутствует сильный дисбаланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</n>\n",
    "Отчистим комментарий от лишних символов, приведем все к нижнему регисстру и к своей лемме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(50000).reset_index(drop=True)\n",
    "def clear_text(string):\n",
    "    new_string = re.sub(r\"(?:\\n|\\r)\", \"\", string)\n",
    "    new_string = re.sub(r'[^a-zA-Z\\ ]', \" \", new_string).strip()\n",
    "    return new_string\n",
    "data['text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45459</td>\n",
       "      <td>firstly  please kindly specifically say what here is an inappropriate cut and paste  afaik this was lastly moved with move button  careful with reading the edit history  please secondly  on what do you base an erroneous claim that russian patronymic   daughter of george   as part of name is georgievna  not yurievna   georgievna rather is sort of semi anglic german western bastardized version  whereas   yurij   is the translitered russian name  on basis of which patronymics too should be  please explain your credentials in assessing georgievna to be better than yurievna  please give evidence that georgievna is used by modern high quality texts  instead of yurievna  georgievna may have been used in semi german anglic very old texts  and in low quality texts  afaik  but never in today high quality works  thirdly  you apprently missed the point  the   of greece   is the new element suggested above  have you checked naming conventions of non reigning royals  what is your reasoning for t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27727</td>\n",
       "      <td>vandalyze my goodness  did you bother to read this  my first impression about you was that you were a super sensitive    year old with a trigger happy finger  after reading through your bio  i came up with a slightly different view  you didn t read or comprehend the importance of my suggestion  i will continue pursuing this and  if you wish to discuss it with me  please contact me via my user page   wangtopgun  i offer full disclosure about myself  my background  various careers  etc  i suggest you read before you hit the delete key  because you may be missing a gem  all the best  dean garner vandalyze i want this topic to be unprotected  so i suggest you do so  do you wanna go to war with me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32478</td>\n",
       "      <td>hi trpod  i hear you are still being one of the   horsemen of wikipedia  trying to astroturf the narrative on the gamergate controversy page   i congratulate you on your sterling efforts to maintain wikipedia s most uniquely biased article   i hope you let us all know how much you are being paid at the end of this   i hope you aren t doing it as a freebie   kiss kiss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41349</td>\n",
       "      <td>utc  i completely agree  not only does the guy have penis problem   but the   figures are extremely anorexic aswell  someone may also be partially motivated to promote exaggerated stereotypes  the picture before with moderate figure had been used for long time and is good representation of average human figure   talk  talk   contribs          march</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73613</td>\n",
       "      <td>you are the one attacking and libelling me   i don t follow you around or make a nuisance on your talk page   learn respect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0       45459   \n",
       "1       27727   \n",
       "2       32478   \n",
       "3       41349   \n",
       "4       73613   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  firstly  please kindly specifically say what here is an inappropriate cut and paste  afaik this was lastly moved with move button  careful with reading the edit history  please secondly  on what do you base an erroneous claim that russian patronymic   daughter of george   as part of name is georgievna  not yurievna   georgievna rather is sort of semi anglic german western bastardized version  whereas   yurij   is the translitered russian name  on basis of which patronymics too should be  please explain your credentials in assessing georgievna to be better than yurievna  please give evidence that georgievna is used by modern high quality texts  instead of yurievna  georgievna may have been used in semi german anglic very old texts  and in low quality texts  afaik  but never in today high quality works  thirdly  you apprently missed the point  the   of greece   is the new element suggested above  have you checked naming conventions of non reigning royals  what is your reasoning for t...   \n",
       "1                                                                                                                                                                                                                                                                                                            vandalyze my goodness  did you bother to read this  my first impression about you was that you were a super sensitive    year old with a trigger happy finger  after reading through your bio  i came up with a slightly different view  you didn t read or comprehend the importance of my suggestion  i will continue pursuing this and  if you wish to discuss it with me  please contact me via my user page   wangtopgun  i offer full disclosure about myself  my background  various careers  etc  i suggest you read before you hit the delete key  because you may be missing a gem  all the best  dean garner vandalyze i want this topic to be unprotected  so i suggest you do so  do you wanna go to war with me   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        hi trpod  i hear you are still being one of the   horsemen of wikipedia  trying to astroturf the narrative on the gamergate controversy page   i congratulate you on your sterling efforts to maintain wikipedia s most uniquely biased article   i hope you let us all know how much you are being paid at the end of this   i hope you aren t doing it as a freebie   kiss kiss   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           utc  i completely agree  not only does the guy have penis problem   but the   figures are extremely anorexic aswell  someone may also be partially motivated to promote exaggerated stereotypes  the picture before with moderate figure had been used for long time and is good representation of average human figure   talk  talk   contribs          march   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              you are the one attacking and libelling me   i don t follow you around or make a nuisance on your talk page   learn respect   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemm_list = [lemmatizer.lemmatize(w) for w in word_list]\n",
    "    lemm_text = \" \".join(lemm_list)\n",
    "    return lemm_text\n",
    "data['text'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> В данных нет пропусков, дубликатов, ошибок в типах данных. Текст в сообщениях подготовлен к обучения: приведен к нижнему регистру и своей лемме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['toxic'], axis=1)\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод векторизации \"TF-IDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train['text'].values\n",
    "corpus_test = features_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(ngram_range=(1,2),\n",
    "                               stop_words=stop_words,\n",
    "                               min_df=3,\n",
    "                               max_df=0.9,\n",
    "                               #strip_accents='unicode',\n",
    "                               use_idf=1,\n",
    "                               smooth_idf=1,\n",
    "                               sublinear_tf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = count_tf_idf.fit(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf_df.transform(corpus_train)\n",
    "x_test = tf_df.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = RandomState(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>*Обучим модель LogisticRegression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8}\n",
      "0.7550633580488274\n",
      "CPU times: user 3min 39s, sys: 3min 12s, total: 6min 52s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(class_weight='balanced', solver='liblinear', max_iter=1000)\n",
    "params = dict(C=np.arange(1, 20, 1))\n",
    "search_for_lr = RandomizedSearchCV(model_lr, \n",
    "                                   params,\n",
    "                                   scoring='f1',\n",
    "                                   random_state=state)\n",
    "search_for_lr.fit(x_train, y_train)\n",
    "print(search_for_lr.best_params_)\n",
    "print(search_for_lr.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>*Обучим модель RandomForestClassifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'min_samples_leaf': 3, 'max_depth': 90}\n",
      "0.5378645802415719\n",
      "CPU times: user 4min 2s, sys: 0 ns, total: 4min 2s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(class_weight='balanced')\n",
    "params = dict(n_estimators=np.arange(10, 100, 10),\n",
    "              max_depth=np.arange(10, 100, 10),\n",
    "              min_samples_leaf=[1, 3])\n",
    "search_for_rf = RandomizedSearchCV(model_rf, \n",
    "                                   params,\n",
    "                                   scoring='f1',\n",
    "                                   random_state=state)\n",
    "search_for_rf.fit(x_train, y_train)\n",
    "print(search_for_rf.best_params_)\n",
    "print(search_for_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>*Обучим модель LinearSVC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.7000000000000001}\n",
      "0.7537884410727222\n",
      "CPU times: user 13.2 s, sys: 0 ns, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lsvc = LinearSVC(random_state=state, class_weight='balanced')\n",
    "params = dict(C=np.arange(0.1, 1, 0.1))\n",
    "search_for_lsvc = RandomizedSearchCV(model_lsvc, \n",
    "                                   params,\n",
    "                                   scoring='f1',\n",
    "                                   random_state=state)\n",
    "search_for_lsvc.fit(x_train, y_train)\n",
    "print(search_for_lsvc.best_params_)\n",
    "print(search_for_lsvc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Вывод: было обучено 3 разных модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 выше у модели LogisticRegression, поэтому протестируем ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.755063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.537865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.753788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель        F1\n",
       "0  LogisticRegression  0.755063\n",
       "1        RandomForest  0.537865\n",
       "2           LinearSVC  0.753788"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['LogisticRegression', 'RandomForest', 'LinearSVC']\n",
    "f1 = [search_for_lr.best_score_, search_for_rf.best_score_, search_for_lsvc.best_score_]\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Модель': models, \n",
    "    'F1': f1\n",
    "}) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7607407407407407\n"
     ]
    }
   ],
   "source": [
    "test_model_lr = LogisticRegression(solver='liblinear',\n",
    "                                   C=9,\n",
    "                                   class_weight='balanced',\n",
    "                                   random_state=state,\n",
    "                                   max_iter=1000)\n",
    "test_model_lr.fit(x_train, y_train)\n",
    "f1_test_lr = f1_score(y_test, test_model_lr.predict(x_test))\n",
    "print(f1_test_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Наилучшие показатели у модели \"Логистическая регрессия\". Результат на тестовой выборке: f1 = 0.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> В этой работе я создавал модель, которая будет определять токсичные комментарии. Для этого все коментарии были приведены к лемме и нижнему регистру. Затем было обучено 3 модели LogisticRegression, RandomForest, LinearSVC. Логистическая регрессия показала точность выше всех, поэтому ее я проверили на тестовой выборке. F1>0,75 - значит поставленная цель выполнена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2603,
    "start_time": "2023-10-11T19:08:53.825Z"
   },
   {
    "duration": 4197,
    "start_time": "2023-10-11T19:08:57.406Z"
   },
   {
    "duration": 34,
    "start_time": "2023-10-11T19:09:01.605Z"
   },
   {
    "duration": 58,
    "start_time": "2023-10-11T19:09:01.641Z"
   },
   {
    "duration": 265,
    "start_time": "2023-10-11T19:10:02.878Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-11T19:10:34.813Z"
   },
   {
    "duration": 810,
    "start_time": "2023-10-11T19:11:55.553Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-11T19:12:07.270Z"
   },
   {
    "duration": 482,
    "start_time": "2023-10-11T19:13:01.930Z"
   },
   {
    "duration": 28222,
    "start_time": "2023-10-11T19:13:31.177Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-11T20:27:11.110Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-11T20:27:12.493Z"
   },
   {
    "duration": 787,
    "start_time": "2023-10-11T20:27:13.287Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-11T20:27:14.619Z"
   },
   {
    "duration": 5255,
    "start_time": "2023-10-11T20:27:15.677Z"
   },
   {
    "duration": 4668,
    "start_time": "2023-10-11T20:27:22.750Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-11T20:27:28.424Z"
   },
   {
    "duration": 403193,
    "start_time": "2023-10-11T20:27:30.969Z"
   },
   {
    "duration": 1868,
    "start_time": "2023-10-12T08:35:02.103Z"
   },
   {
    "duration": 76,
    "start_time": "2023-10-12T08:35:08.891Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-12T08:35:11.726Z"
   },
   {
    "duration": 1568,
    "start_time": "2023-10-12T08:35:20.386Z"
   },
   {
    "duration": 3340,
    "start_time": "2023-10-12T08:35:21.956Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-12T08:35:25.298Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-12T08:35:25.331Z"
   },
   {
    "duration": 225,
    "start_time": "2023-10-12T08:35:25.345Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-12T08:35:25.572Z"
   },
   {
    "duration": 708,
    "start_time": "2023-10-12T08:35:25.578Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-12T08:35:26.288Z"
   },
   {
    "duration": 189,
    "start_time": "2023-10-12T08:35:26.297Z"
   },
   {
    "duration": 26592,
    "start_time": "2023-10-12T08:35:26.489Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-12T08:35:53.083Z"
   },
   {
    "duration": 21,
    "start_time": "2023-10-12T08:35:53.089Z"
   },
   {
    "duration": 736,
    "start_time": "2023-10-12T08:35:53.111Z"
   },
   {
    "duration": 45,
    "start_time": "2023-10-12T08:35:53.849Z"
   },
   {
    "duration": 4500,
    "start_time": "2023-10-12T08:35:53.895Z"
   },
   {
    "duration": 4265,
    "start_time": "2023-10-12T08:35:58.397Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-12T08:36:02.664Z"
   },
   {
    "duration": 415180,
    "start_time": "2023-10-12T08:36:02.669Z"
   },
   {
    "duration": 124,
    "start_time": "2023-10-12T08:44:19.655Z"
   },
   {
    "duration": 8634,
    "start_time": "2023-10-12T08:44:32.912Z"
   },
   {
    "duration": 8291,
    "start_time": "2023-10-12T08:46:45.457Z"
   },
   {
    "duration": 9355,
    "start_time": "2023-10-12T08:47:05.891Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-12T08:54:27.880Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-12T08:54:58.062Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-12T08:55:21.161Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-12T09:07:39.846Z"
   },
   {
    "duration": 29,
    "start_time": "2023-10-12T09:07:55.730Z"
   },
   {
    "duration": 108,
    "start_time": "2023-10-12T09:16:45.484Z"
   },
   {
    "duration": 160408,
    "start_time": "2023-10-12T09:24:16.068Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-12T09:33:57.026Z"
   },
   {
    "duration": 91,
    "start_time": "2023-10-12T09:34:36.901Z"
   },
   {
    "duration": 98,
    "start_time": "2023-10-12T09:37:48.799Z"
   },
   {
    "duration": 137,
    "start_time": "2023-10-12T09:38:13.439Z"
   },
   {
    "duration": 251231,
    "start_time": "2023-10-12T09:39:58.229Z"
   },
   {
    "duration": 82,
    "start_time": "2023-10-12T10:15:30.456Z"
   },
   {
    "duration": 3596,
    "start_time": "2023-10-12T10:16:33.875Z"
   },
   {
    "duration": 122,
    "start_time": "2023-10-12T15:13:47.937Z"
   },
   {
    "duration": 2021,
    "start_time": "2023-10-12T15:13:56.302Z"
   },
   {
    "duration": 2497,
    "start_time": "2023-10-12T15:13:58.324Z"
   },
   {
    "duration": 33,
    "start_time": "2023-10-12T15:14:00.822Z"
   },
   {
    "duration": 70,
    "start_time": "2023-10-12T15:14:00.857Z"
   },
   {
    "duration": 277,
    "start_time": "2023-10-12T15:14:00.928Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-12T15:14:01.207Z"
   },
   {
    "duration": 907,
    "start_time": "2023-10-12T15:14:01.214Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-12T15:14:02.123Z"
   },
   {
    "duration": 204,
    "start_time": "2023-10-12T15:14:02.143Z"
   },
   {
    "duration": 26628,
    "start_time": "2023-10-12T15:14:02.350Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-12T15:14:28.980Z"
   },
   {
    "duration": 38,
    "start_time": "2023-10-12T15:14:28.986Z"
   },
   {
    "duration": 663,
    "start_time": "2023-10-12T15:14:29.026Z"
   },
   {
    "duration": 19,
    "start_time": "2023-10-12T15:14:29.690Z"
   },
   {
    "duration": 4560,
    "start_time": "2023-10-12T15:14:29.711Z"
   },
   {
    "duration": 4417,
    "start_time": "2023-10-12T15:14:34.273Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-12T15:14:38.691Z"
   },
   {
    "duration": 378349,
    "start_time": "2023-10-12T15:14:38.696Z"
   },
   {
    "duration": 5807,
    "start_time": "2023-10-12T15:20:57.046Z"
   },
   {
    "duration": 158413,
    "start_time": "2023-10-12T15:21:02.855Z"
   },
   {
    "duration": 3829,
    "start_time": "2023-10-12T15:23:41.270Z"
   },
   {
    "duration": 75,
    "start_time": "2023-10-12T15:23:45.101Z"
   },
   {
    "duration": 267,
    "start_time": "2023-10-12T15:27:04.711Z"
   },
   {
    "duration": 129,
    "start_time": "2023-10-12T15:27:35.944Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-12T15:29:10.519Z"
   },
   {
    "duration": 257,
    "start_time": "2023-10-12T15:29:19.177Z"
   },
   {
    "duration": 27,
    "start_time": "2023-10-12T15:29:50.543Z"
   },
   {
    "duration": 2060,
    "start_time": "2023-10-14T08:19:58.962Z"
   },
   {
    "duration": 2510,
    "start_time": "2023-10-14T08:20:01.025Z"
   },
   {
    "duration": 35,
    "start_time": "2023-10-14T08:20:03.536Z"
   },
   {
    "duration": 43,
    "start_time": "2023-10-14T08:20:03.574Z"
   },
   {
    "duration": 283,
    "start_time": "2023-10-14T08:20:03.620Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-14T08:20:03.905Z"
   },
   {
    "duration": 915,
    "start_time": "2023-10-14T08:20:03.914Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-14T08:20:04.831Z"
   },
   {
    "duration": 254,
    "start_time": "2023-10-14T08:20:04.840Z"
   },
   {
    "duration": 31290,
    "start_time": "2023-10-14T08:20:05.097Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-14T08:20:36.390Z"
   },
   {
    "duration": 22,
    "start_time": "2023-10-14T08:20:36.398Z"
   },
   {
    "duration": 733,
    "start_time": "2023-10-14T08:20:36.422Z"
   },
   {
    "duration": 21,
    "start_time": "2023-10-14T08:20:37.158Z"
   },
   {
    "duration": 5025,
    "start_time": "2023-10-14T08:20:37.181Z"
   },
   {
    "duration": 4667,
    "start_time": "2023-10-14T08:20:42.208Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T08:20:46.877Z"
   },
   {
    "duration": 388082,
    "start_time": "2023-10-14T08:20:46.882Z"
   },
   {
    "duration": 10402,
    "start_time": "2023-10-14T08:27:14.966Z"
   },
   {
    "duration": 181721,
    "start_time": "2023-10-14T08:27:25.370Z"
   },
   {
    "duration": 4168,
    "start_time": "2023-10-14T08:30:27.093Z"
   },
   {
    "duration": 229,
    "start_time": "2023-10-14T08:30:31.262Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-14T08:30:31.492Z"
   },
   {
    "duration": 147,
    "start_time": "2023-10-14T08:43:48.028Z"
   },
   {
    "duration": 588,
    "start_time": "2023-10-14T08:43:54.889Z"
   },
   {
    "duration": 487,
    "start_time": "2023-10-14T08:46:30.327Z"
   },
   {
    "duration": 1933,
    "start_time": "2023-10-14T09:00:39.451Z"
   },
   {
    "duration": 945,
    "start_time": "2023-10-14T09:00:41.386Z"
   },
   {
    "duration": 38,
    "start_time": "2023-10-14T09:00:42.333Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-14T09:00:42.373Z"
   },
   {
    "duration": 259,
    "start_time": "2023-10-14T09:00:42.387Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-14T09:00:42.648Z"
   },
   {
    "duration": 328,
    "start_time": "2023-10-14T09:00:42.656Z"
   },
   {
    "duration": 949,
    "start_time": "2023-10-14T09:00:42.987Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.938Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.939Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.940Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.942Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.944Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.945Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.947Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.949Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.950Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.952Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.954Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.955Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.957Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.958Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.959Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T09:00:43.961Z"
   },
   {
    "duration": 2097,
    "start_time": "2023-10-14T09:02:13.355Z"
   },
   {
    "duration": 953,
    "start_time": "2023-10-14T09:02:15.454Z"
   },
   {
    "duration": 38,
    "start_time": "2023-10-14T09:02:16.410Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-14T09:02:16.451Z"
   },
   {
    "duration": 257,
    "start_time": "2023-10-14T09:02:16.469Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-14T09:02:16.728Z"
   },
   {
    "duration": 334,
    "start_time": "2023-10-14T09:02:16.746Z"
   },
   {
    "duration": 749,
    "start_time": "2023-10-14T09:02:17.082Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-14T09:02:17.832Z"
   },
   {
    "duration": 166,
    "start_time": "2023-10-14T09:02:17.848Z"
   },
   {
    "duration": 30837,
    "start_time": "2023-10-14T09:02:18.015Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T09:02:48.854Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-14T09:02:48.861Z"
   },
   {
    "duration": 725,
    "start_time": "2023-10-14T09:02:48.879Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-14T09:02:49.606Z"
   },
   {
    "duration": 5207,
    "start_time": "2023-10-14T09:02:49.623Z"
   },
   {
    "duration": 5038,
    "start_time": "2023-10-14T09:02:54.832Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T09:02:59.872Z"
   },
   {
    "duration": 448474,
    "start_time": "2023-10-14T09:02:59.877Z"
   },
   {
    "duration": 9612,
    "start_time": "2023-10-14T09:10:28.354Z"
   },
   {
    "duration": 187369,
    "start_time": "2023-10-14T09:10:38.047Z"
   },
   {
    "duration": 4391,
    "start_time": "2023-10-14T09:13:45.418Z"
   },
   {
    "duration": 447,
    "start_time": "2023-10-14T09:13:49.811Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-14T09:13:50.260Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-14T09:24:14.025Z"
   },
   {
    "duration": 1940,
    "start_time": "2023-10-14T09:34:29.828Z"
   },
   {
    "duration": 969,
    "start_time": "2023-10-14T09:34:31.770Z"
   },
   {
    "duration": 35,
    "start_time": "2023-10-14T09:34:32.741Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-14T09:34:32.777Z"
   },
   {
    "duration": 272,
    "start_time": "2023-10-14T09:34:32.790Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-14T09:34:33.063Z"
   },
   {
    "duration": 356,
    "start_time": "2023-10-14T09:34:33.071Z"
   },
   {
    "duration": 739,
    "start_time": "2023-10-14T09:34:33.429Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-14T09:34:34.170Z"
   },
   {
    "duration": 173,
    "start_time": "2023-10-14T09:34:34.179Z"
   },
   {
    "duration": 29928,
    "start_time": "2023-10-14T09:34:34.354Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-14T09:35:04.284Z"
   },
   {
    "duration": 46,
    "start_time": "2023-10-14T09:35:04.294Z"
   },
   {
    "duration": 740,
    "start_time": "2023-10-14T09:35:04.343Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T09:35:05.085Z"
   },
   {
    "duration": 4980,
    "start_time": "2023-10-14T09:35:05.092Z"
   },
   {
    "duration": 4767,
    "start_time": "2023-10-14T09:35:10.073Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T09:35:14.842Z"
   },
   {
    "duration": 427606,
    "start_time": "2023-10-14T09:35:14.848Z"
   },
   {
    "duration": 11892,
    "start_time": "2023-10-14T09:42:22.468Z"
   },
   {
    "duration": 179212,
    "start_time": "2023-10-14T09:42:34.362Z"
   },
   {
    "duration": 4161,
    "start_time": "2023-10-14T09:45:33.576Z"
   },
   {
    "duration": 25,
    "start_time": "2023-10-14T09:45:37.739Z"
   },
   {
    "duration": 1741,
    "start_time": "2023-10-14T13:45:03.293Z"
   },
   {
    "duration": 3119,
    "start_time": "2023-10-14T13:45:05.035Z"
   },
   {
    "duration": 31,
    "start_time": "2023-10-14T13:45:08.156Z"
   },
   {
    "duration": 46,
    "start_time": "2023-10-14T13:45:08.189Z"
   },
   {
    "duration": 240,
    "start_time": "2023-10-14T13:45:08.236Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T13:45:08.477Z"
   },
   {
    "duration": 300,
    "start_time": "2023-10-14T13:45:08.484Z"
   },
   {
    "duration": 672,
    "start_time": "2023-10-14T13:45:08.785Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-14T13:45:09.458Z"
   },
   {
    "duration": 173,
    "start_time": "2023-10-14T13:45:09.467Z"
   },
   {
    "duration": 25762,
    "start_time": "2023-10-14T13:45:09.641Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T13:45:35.405Z"
   },
   {
    "duration": 20,
    "start_time": "2023-10-14T13:45:35.411Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-14T13:45:35.432Z"
   },
   {
    "duration": 139,
    "start_time": "2023-10-14T13:45:35.445Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T13:45:35.586Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T13:45:35.587Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T13:45:35.588Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T13:45:35.589Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T13:45:35.590Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T13:45:35.591Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:43:31.790Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-14T14:43:33.068Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:43:48.101Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-14T14:43:49.606Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:43:55.304Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T14:43:57.304Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T14:44:01.484Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:44:04.656Z"
   },
   {
    "duration": 107,
    "start_time": "2023-10-14T14:44:23.257Z"
   },
   {
    "duration": 99,
    "start_time": "2023-10-14T14:44:23.366Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-14T14:44:23.467Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-14T14:44:23.479Z"
   },
   {
    "duration": 99,
    "start_time": "2023-10-14T14:44:38.190Z"
   },
   {
    "duration": 84,
    "start_time": "2023-10-14T14:45:28.337Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:45:34.791Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-14T14:45:37.087Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:45:54.526Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:45:55.598Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:45:56.813Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:45:57.368Z"
   },
   {
    "duration": 99,
    "start_time": "2023-10-14T14:46:03.260Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:47:24.919Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:47:25.626Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:47:26.237Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:47:26.740Z"
   },
   {
    "duration": 106,
    "start_time": "2023-10-14T14:47:30.958Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:47:53.368Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-14T14:47:54.418Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:48:10.676Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-14T14:48:11.557Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:48:17.303Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-14T14:48:17.856Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-14T14:48:24.448Z"
   },
   {
    "duration": 22,
    "start_time": "2023-10-14T14:48:25.441Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:49:56.211Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-14T14:49:57.001Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:50:02.027Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T14:50:02.756Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:50:08.759Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:50:09.282Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:50:10.765Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:50:11.294Z"
   },
   {
    "duration": 129,
    "start_time": "2023-10-14T14:50:14.729Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:53:50.020Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T14:53:50.889Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-14T14:53:51.405Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:53:51.950Z"
   },
   {
    "duration": 92,
    "start_time": "2023-10-14T14:53:54.456Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:54:03.903Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:54:04.343Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-14T14:54:04.858Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-14T14:54:05.372Z"
   },
   {
    "duration": 89,
    "start_time": "2023-10-14T14:54:07.498Z"
   },
   {
    "duration": 2054,
    "start_time": "2023-10-15T13:17:20.177Z"
   },
   {
    "duration": 2280,
    "start_time": "2023-10-15T13:17:22.233Z"
   },
   {
    "duration": 36,
    "start_time": "2023-10-15T13:17:24.516Z"
   },
   {
    "duration": 65,
    "start_time": "2023-10-15T13:17:24.554Z"
   },
   {
    "duration": 242,
    "start_time": "2023-10-15T13:17:24.620Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-15T13:17:24.864Z"
   },
   {
    "duration": 311,
    "start_time": "2023-10-15T13:17:24.871Z"
   },
   {
    "duration": 678,
    "start_time": "2023-10-15T13:17:25.184Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-15T13:17:25.864Z"
   },
   {
    "duration": 332,
    "start_time": "2023-10-15T13:17:25.878Z"
   },
   {
    "duration": 26342,
    "start_time": "2023-10-15T13:17:26.212Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-15T13:17:52.556Z"
   },
   {
    "duration": 54,
    "start_time": "2023-10-15T13:17:52.563Z"
   },
   {
    "duration": 28,
    "start_time": "2023-10-15T13:17:52.618Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-15T13:17:52.648Z"
   },
   {
    "duration": 34,
    "start_time": "2023-10-15T13:17:52.680Z"
   },
   {
    "duration": 61,
    "start_time": "2023-10-15T13:17:52.716Z"
   },
   {
    "duration": 287,
    "start_time": "2023-10-15T13:17:52.779Z"
   },
   {
    "duration": 100,
    "start_time": "2023-10-15T13:17:53.068Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-15T13:17:53.170Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-15T13:17:53.183Z"
   },
   {
    "duration": 1855,
    "start_time": "2023-10-15T13:19:44.959Z"
   },
   {
    "duration": 946,
    "start_time": "2023-10-15T13:19:46.817Z"
   },
   {
    "duration": 33,
    "start_time": "2023-10-15T13:19:47.765Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-15T13:19:47.801Z"
   },
   {
    "duration": 276,
    "start_time": "2023-10-15T13:19:47.834Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-15T13:19:48.117Z"
   },
   {
    "duration": 304,
    "start_time": "2023-10-15T13:19:48.127Z"
   },
   {
    "duration": 716,
    "start_time": "2023-10-15T13:19:48.433Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-15T13:19:49.151Z"
   },
   {
    "duration": 243,
    "start_time": "2023-10-15T13:19:49.160Z"
   },
   {
    "duration": 25812,
    "start_time": "2023-10-15T13:19:49.405Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-15T13:20:15.219Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-15T13:20:15.226Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-15T13:20:15.241Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-15T13:20:15.250Z"
   },
   {
    "duration": 4027,
    "start_time": "2023-10-15T13:20:15.259Z"
   },
   {
    "duration": 3479,
    "start_time": "2023-10-15T13:20:19.288Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-15T13:20:22.769Z"
   },
   {
    "duration": 421855,
    "start_time": "2023-10-15T13:20:22.774Z"
   },
   {
    "duration": 247965,
    "start_time": "2023-10-15T13:27:24.631Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-15T13:31:32.598Z"
   },
   {
    "duration": 9417,
    "start_time": "2023-10-15T13:31:32.607Z"
   },
   {
    "duration": 49,
    "start_time": "2024-02-07T10:08:49.918Z"
   },
   {
    "duration": 1957,
    "start_time": "2024-02-07T10:08:53.490Z"
   },
   {
    "duration": 3317,
    "start_time": "2024-02-07T10:09:00.627Z"
   },
   {
    "duration": 32,
    "start_time": "2024-02-07T10:09:04.701Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-07T10:09:09.471Z"
   },
   {
    "duration": 11,
    "start_time": "2024-02-07T10:09:10.231Z"
   },
   {
    "duration": 1680,
    "start_time": "2024-02-07T10:20:28.150Z"
   },
   {
    "duration": 899,
    "start_time": "2024-02-07T10:20:29.832Z"
   },
   {
    "duration": 36,
    "start_time": "2024-02-07T10:20:30.733Z"
   },
   {
    "duration": 73,
    "start_time": "2024-02-07T10:20:30.771Z"
   },
   {
    "duration": 48,
    "start_time": "2024-02-07T10:20:30.847Z"
   },
   {
    "duration": 261,
    "start_time": "2024-02-07T10:20:30.897Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-07T10:20:31.160Z"
   },
   {
    "duration": 341,
    "start_time": "2024-02-07T10:20:31.167Z"
   },
   {
    "duration": 718,
    "start_time": "2024-02-07T10:20:31.510Z"
   },
   {
    "duration": 9,
    "start_time": "2024-02-07T10:20:32.230Z"
   },
   {
    "duration": 270,
    "start_time": "2024-02-07T10:20:32.241Z"
   },
   {
    "duration": 27463,
    "start_time": "2024-02-07T10:20:32.513Z"
   },
   {
    "duration": 8,
    "start_time": "2024-02-07T10:20:59.978Z"
   },
   {
    "duration": 14,
    "start_time": "2024-02-07T10:20:59.993Z"
   },
   {
    "duration": 24,
    "start_time": "2024-02-07T10:21:00.008Z"
   },
   {
    "duration": 31,
    "start_time": "2024-02-07T10:21:00.034Z"
   },
   {
    "duration": 4068,
    "start_time": "2024-02-07T10:21:00.066Z"
   },
   {
    "duration": 3473,
    "start_time": "2024-02-07T10:21:04.136Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-07T10:21:07.611Z"
   },
   {
    "duration": 242733,
    "start_time": "2024-02-07T10:27:52.895Z"
   },
   {
    "duration": 232,
    "start_time": "2024-02-07T10:31:55.630Z"
   },
   {
    "duration": 85,
    "start_time": "2024-02-07T10:31:55.864Z"
   },
   {
    "duration": 14,
    "start_time": "2024-02-07T10:31:55.951Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T10:31:55.967Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-07T10:48:41.437Z"
   },
   {
    "duration": 412579,
    "start_time": "2024-02-07T10:49:12.339Z"
   },
   {
    "duration": 86,
    "start_time": "2024-02-07T10:56:04.993Z"
   },
   {
    "duration": 96,
    "start_time": "2024-02-07T10:56:05.080Z"
   },
   {
    "duration": 11,
    "start_time": "2024-02-07T10:56:05.178Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T10:56:05.190Z"
   },
   {
    "duration": 13250,
    "start_time": "2024-02-07T11:04:03.098Z"
   },
   {
    "duration": 1227973,
    "start_time": "2024-02-07T11:04:29.966Z"
   },
   {
    "duration": 10,
    "start_time": "2024-02-07T11:24:57.942Z"
   },
   {
    "duration": 9240,
    "start_time": "2024-02-07T11:24:57.954Z"
   },
   {
    "duration": 9,
    "start_time": "2024-02-07T11:27:09.139Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
